\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}
\input{../../style/preamble}

% latex-math includes as needed
\input{../../latex-math/basic-math}
\input{../../latex-math/basic-ml}

% Lecture title always has to be there
\title{Algorithms and Data Structures}

\begin{document}

\titlemeta{% Chunk title (example: CART, Forests, Boosting, ...), can be empty
Matrix Approximation
}{% Lecture title
Topic Extraction
}{% Relative path to title page image: Can be empty but must not start with slides/
}{% Learning goals, wrapped inside itemize environment
  \item Topic Extraction
}
%\lecture{CIM1 Statistical Computing}


\begin{vbframe}{Application: Topic Extraction}

Often online articles refer to articles with similar content, e.g.

\begin{center}
	\textbf{\emph{\href{https://www.nytimes.com/2017/11/05/technology/machine-learning-artificial-intelligence-ai.html?rref=collection\%2Fsectioncollection\%2Ftechnology&action=click&contentCollection=technology&region=rank&module=package&version=highlights&contentPlacement=2&pgtype=sectionfront}{Building AI that Can Build AI}}} \\
	$\Big\downarrow$ \footnotesize{"related"}\\
	\normalsize \textbf{	\emph{\href{https://www.nytimes.com/2017/09/10/business/warehouse-robots-learning.html?action=click&contentCollection=Technology&module=RelatedCoverage&region=Marginalia&pgtype=article}{In the Future, Warehouse Robots Will Learn on Their Own}}} \\
	$\Big\downarrow$ \footnotesize "related"\\
	\normalsize\textbf{	\emph{\href{https://www.nytimes.com/2017/09/10/technology/amazon-robots-workers.html?action=click&contentCollection=Business\%20Day&module=RelatedCoverage&region=Marginalia&pgtype=article}{As Amazon Pushes Forward With Robots, Workers Find New Roles}}}
\end{center}

The first two articles should definitely have one topic in common, just like the last two articles. We want to extract these two topics using a NMF.

\framebreak

We set up the corresponding document-term matrix.

\lz

\begin{footnotesize}
\begin{verbatim}
##                doc1 doc2 doc3
## accelerate      1    0    0
## accelerating    1    0    0
## accurately      1    0    0
## across          1    1    2
## address         1    1    0
## adjust          1    0    0
\end{verbatim}
\end{footnotesize}
%<<echo = F>>=
%options(digits = 2)
%@

%<<echo = F>>=
%tdm = readRDS("rsrc/tdm")
%@

%<<echo=F>>=
%head(tdm)
%@

\framebreak

We "search" two topics linking the articles.
\vspace{0.2cm}

\begin{footnotesize}
\begin{verbatim}
set.seed(1)
res = nmf(tdm, 2, "Frobenius")
\end{verbatim}


\lz
\begin{verbatim}
##                topic1   topic2
## accelerate     0.0016   3.8e-11
## accelerating   0.0016   3.8e-11
## accurately     0.0016   3.8e-11
## across         0.0023   4.1e-03
## address        0.0026   6.3e-05
## adjust         0.0016   3.8e-11
\end{verbatim}
\end{footnotesize}
%<<>>=
%set.seed(1)
%res = nmf(tdm, 2, "Frobenius")
%@

%<<echo = F>>=
%wordmatrix = as.data.frame(basis(res)) # topic-word-matrix

%wordmatrix$word = rownames(wordmatrix)
%colnames(wordmatrix) = c("topic1", "topic2", "word")

%head(wordmatrix)[1:2]
%@

\normalsize
\end{vbframe}

\begin{vbframe}{Topic Extraction}

For both topics, we print the $30$ words with the largest values in the columns of matrix $\mathbf{W}$. The size of the word in the wordcloud is determined by the value of $w_{ij}$ (placement of the word is completely random).\\

%\begin{center}
%	\includegraphics[width = 0.4\textwidth]{figure_man/wordcloud01.png}
%\end{center}
\begin{figure}
	\subfloat[Topic 1]{\includegraphics[width=0.4\textwidth]{figure_man/wordcloud01.png}}
	\subfloat[Topic 2]{\includegraphics[width=0.4\textwidth]{figure_man/wordcloud02.png}}\\
  \end{figure}
%<<echo = F, out.width='70%', fig.align='center'>>=
%df = wordmatrix[order(- wordmatrix[, 1]), ]
%df = as.data.frame(df[1:30, ])

%wordcloud(df$word,df$topic1)
%@

\end{vbframe}

%\begin{vbframe}{Topic Extraction: Topic 2}
%\lz
%\begin{center}
%	\includegraphics[width = 0.4\textwidth]{figure_man/wordcloud02.png}
%\end{center}


%<<echo = F, fig.align='center'>>=
%df = wordmatrix[order(- wordmatrix[, 2]), ]
%df = as.data.frame(df[1:30, ])

%wordcloud(df$word,df$topic2)
%@

%\end{vbframe}

\begin{vbframe}{Topic Extraction: Coefficient matrix $\mathbf{H}$}

\footnotesize
\vspace{0.3cm}
\begin{verbatim}
H

##         topic 1   topic 2
## doc1    4.5e+02   1.8e-09
## doc2    2.9e+02   5.8e+01
## doc3    1.6e-09   4.9e+02
\end{verbatim}

%<<echo = F>>=
%H = t(coef(res))
%colnames(H) = c("topic 1", "topic 2")
%@

%<<>>=
%H
%@

\normalsize
The coefficient matrix shows: The first article clearly refers to the first extracted topic, article 3 clearly to the last.
Article 2 addresses both topics.

\vfill

\begin{footnotesize}
Implementation in R: \url{https://rpubs.com/JanpuHou/300168}
\end{footnotesize}

\end{vbframe}

\endlecture
\end{document}







